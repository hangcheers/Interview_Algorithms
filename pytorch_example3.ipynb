{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# image transformations can be chained together using Compose\n",
    "# transform the PILImage to Tensors of normalized range [-1, 1]\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                       download=False, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                         shuffle=True)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                      download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                        shuffle=False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define neural networks.   \n",
    "Define loss function.   \n",
    "Train the network on the training data{ Compute Loss and use the optimizer to update the weights of the network during training process}.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.304\n",
      "[1,  4000] loss: 2.302\n",
      "[1,  6000] loss: 2.300\n",
      "[1,  8000] loss: 2.296\n",
      "[1, 10000] loss: 2.287\n",
      "[1, 12000] loss: 2.258\n",
      "[2,  2000] loss: 2.133\n",
      "[2,  4000] loss: 2.045\n",
      "[2,  6000] loss: 1.978\n",
      "[2,  8000] loss: 1.929\n",
      "[2, 10000] loss: 1.882\n",
      "[2, 12000] loss: 1.852\n",
      "[3,  2000] loss: 1.795\n",
      "[3,  4000] loss: 1.751\n",
      "[3,  6000] loss: 1.696\n",
      "[3,  8000] loss: 1.671\n",
      "[3, 10000] loss: 1.631\n",
      "[3, 12000] loss: 1.625\n",
      "[4,  2000] loss: 1.587\n",
      "[4,  4000] loss: 1.586\n",
      "[4,  6000] loss: 1.576\n",
      "[4,  8000] loss: 1.554\n",
      "[4, 10000] loss: 1.536\n",
      "[4, 12000] loss: 1.519\n",
      "[5,  2000] loss: 1.505\n",
      "[5,  4000] loss: 1.510\n",
      "[5,  6000] loss: 1.486\n",
      "[5,  8000] loss: 1.490\n",
      "[5, 10000] loss: 1.461\n",
      "[5, 12000] loss: 1.436\n",
      "[6,  2000] loss: 1.432\n",
      "[6,  4000] loss: 1.444\n",
      "[6,  6000] loss: 1.406\n",
      "[6,  8000] loss: 1.409\n",
      "[6, 10000] loss: 1.385\n",
      "[6, 12000] loss: 1.385\n",
      "[7,  2000] loss: 1.388\n",
      "[7,  4000] loss: 1.335\n",
      "[7,  6000] loss: 1.347\n",
      "[7,  8000] loss: 1.343\n",
      "[7, 10000] loss: 1.337\n",
      "[7, 12000] loss: 1.334\n",
      "[8,  2000] loss: 1.320\n",
      "[8,  4000] loss: 1.287\n",
      "[8,  6000] loss: 1.294\n",
      "[8,  8000] loss: 1.286\n",
      "[8, 10000] loss: 1.302\n",
      "[8, 12000] loss: 1.269\n",
      "[9,  2000] loss: 1.254\n",
      "[9,  4000] loss: 1.268\n",
      "[9,  6000] loss: 1.236\n",
      "[9,  8000] loss: 1.243\n",
      "[9, 10000] loss: 1.208\n",
      "[9, 12000] loss: 1.253\n",
      "[10,  2000] loss: 1.200\n",
      "[10,  4000] loss: 1.225\n",
      "[10,  6000] loss: 1.222\n",
      "[10,  8000] loss: 1.188\n",
      "[10, 10000] loss: 1.206\n",
      "[10, 12000] loss: 1.173\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=1e-4, momentum=0.9)\n",
    "# train the model\n",
    "for epoch in range(10):  \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch+1, i+1, running_loss/2000))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "print('Finished Training')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the network on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4])\n",
      "tensor(3)\n",
      "tensor(1)\n",
      "tensor(1)\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "print(labels.size())\n",
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))\n",
    "outputs = net(images)\n",
    "\n",
    "# check the predicted against the ground-truth.\n",
    "# if the prediction is correct, add the sample to the list of correct predictions\n",
    "\n",
    "# torch.max(a, 1) 返回input tensor中每一行中最大的元素，且返回最大元素在这一行的列索引\n",
    "# predicted 即为 列索引\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "for j in range(labels.size(0)):\n",
    "    print(''.join('%5s' % predicted[j]))\n",
    "    \n",
    "# print('Predicted:', ' '.join('%5s' % classes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test on the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 56 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    print(\"accuracy is %d %%\" %(100 * correct/ total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plane 0.0\n",
      "car 0.0\n",
      "bird 0.0\n",
      "cat 24.3\n",
      "deer 25.7\n",
      "dog 25.6\n",
      "frog 0.0\n",
      "horse 25.6\n",
      "ship 0.0\n",
      "truck 0.0\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        output = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        # squeeze 对数据维度进行压缩\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "            \n",
    "for i in range(10):\n",
    "    print(classes[i], 100*class_correct[i]/class_total[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train-evaluate Loop  \n",
    "\n",
    "Train-evaluate every iteration and tracking best accuracy or validation  \n",
    "Save weights if the training iteration produces the best accuracy or validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, trainloader, valloader, optimizer, \n",
    "                       loss_fn, metrics, params, model_dir, restore_file=None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        trainloader: DataLoader for training data\n",
    "        valloader: DataLoader for validation data\n",
    "        metrics: (dict) a dictionary of functions that compute a metric using the output and labels of each batch\n",
    "        model_dir: (string) directory containing config, weights, and log\n",
    "    \"\"\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking point\n",
    "\n",
    "Checkpoint is the term to describe saving a snapshot of the model parameters after every epoch of training. Create checkpoints while training the model and then it allows you to load the saved weights and resume training from any epoch that has a checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import shutil\n",
    "\n",
    "def save_checkpoint(state, is_best, checkpoint):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        state: (dict) contains model's state_dict, may contain optimizer's state_dict\n",
    "        is_best: (bool) True if it is the best model seen till now\n",
    "        checkpoint: (string) folder where parameters are to be saved\n",
    "    \"\"\"\n",
    "    filepath = os.path.join(checkpoint, 'last.pth.tar')\n",
    "    if not os.path.exists(checkpoint):\n",
    "        print('checkpoint directory does not exist')\n",
    "        os.mkdir(checkpoint)\n",
    "    else:\n",
    "        print('checkpoint directory exists')\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        # 移动文件\n",
    "        # shutil.copyfile(\"old file\", \"new file\")\n",
    "        shutil.copyfile(filepath, os.path.join(checkpoint, 'best.pth.tar'))\n",
    "        \n",
    "def load_checkpoint(checkpoint, model, optimizer=None):    \n",
    "    \"\"\"\n",
    "    Args:\n",
    "        checkpoint: (string) filename to be loaded\n",
    "        model: (torch.nn.module) model for which the parameters are loaded\n",
    "        optimizer:(torch.optim) resume optimizer from checkpoint\n",
    "    \"\"\"\n",
    "    if not os.path.exists(checkpoint):\n",
    "        raise(\"File doesn't exist {}\".format(checkpoint))\n",
    "    checkpoint = torch.load(checkpoint)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    \n",
    "    if optimizer:\n",
    "        optimizer.load_state_dict(checkpoint['optim_dict'])\n",
    "    \n",
    "    return checkpoint"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
